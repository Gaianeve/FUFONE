{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PPO Main\n",
        "\n"
      ],
      "metadata": {
        "id": "wXelcCdk2E_-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing libraries and dependencies"
      ],
      "metadata": {
        "id": "DOxSm9hy6S7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# useful for import notebook\n",
        "!pip install import-ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdNtKkPK6R_i",
        "outputId": "1f6856b4-bb8a-4f5e-b445-48559d15e026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting import-ipynb\n",
            "  Downloading import_ipynb-0.1.4-py3-none-any.whl (4.1 kB)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.10/dist-packages (from import-ipynb) (7.34.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from import-ipynb) (5.9.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (67.7.2)\n",
            "Collecting jedi>=0.16 (from IPython->import-ipynb)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (4.8.0)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->import-ipynb) (2.18.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->import-ipynb) (4.19.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from nbformat->import-ipynb) (5.4.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->IPython->import-ipynb) (0.8.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.10.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->IPython->import-ipynb) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->import-ipynb) (0.2.8)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->nbformat->import-ipynb) (3.11.0)\n",
            "Installing collected packages: jedi, import-ipynb\n",
            "Successfully installed import-ipynb-0.1.4 jedi-0.19.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## importing libraries and functions\n"
      ],
      "metadata": {
        "id": "zw5gxH9B2OLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#libraries\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "from distutils.util import strtobool\n",
        "import gym\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.distributions.categorical import Categorical\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "4Bsd8_M52bPt",
        "outputId": "98e69732-6d0e-41f0-b4b2-4f8934f1ab2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import notebook functions\n",
        "import import_ipynb\n",
        "from environment_creator import vectorize_env\n",
        "from Agent_class import Agent\n",
        "from Agent_utils import anneal, collect_data, GAE, PPO_train_agent, evaluate_agent"
      ],
      "metadata": {
        "id": "2_myzRAg4q50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf3b4c32-f7f3-4bfd-d6b4-b9496b84f97d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "importing Jupyter notebook from environment_creator.ipynb\n",
            "importing Jupyter notebook from Agent_class.ipynb\n",
            "importing Jupyter notebook from Agent_utils.ipynb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PARSER ISSUE\n",
        "**Importing the parse_args() function from an another notebook doesn't work, so you need to define the function just ubove the main**\n",
        "\n",
        "For what I have understood, the point is that ther's some problem with the notebook interface, because is user-friendly."
      ],
      "metadata": {
        "id": "J2X7rIwyByOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_args():\n",
        "    # fmt: off\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--exp-name\", type=str, default= \"Cart_Pole_simulation\",\n",
        "        help=\"the name of this experiment\")\n",
        "    parser.add_argument(\"--gym-id\", type=str, default=\"CartPole-v1\",\n",
        "        help=\"the id of the gym environment\")\n",
        "    parser.add_argument(\"--learning-rate\", type=float, default=2.5e-4,\n",
        "        help=\"the learning rate of the optimizer\")\n",
        "    parser.add_argument(\"--seed\", type=int, default=1,\n",
        "        help=\"seed of the experiment\")\n",
        "    parser.add_argument(\"--total-timesteps\", type=int, default=25000,\n",
        "        help=\"total timesteps of the experiments\")\n",
        "    parser.add_argument(\"--torch-deterministic\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
        "        help=\"if toggled, `torch.backends.cudnn.deterministic=False`\")\n",
        "    parser.add_argument(\"--cuda\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
        "        help=\"if toggled, cuda will be enabled by default\")\n",
        "    parser.add_argument(\"--track\", type=lambda x: bool(strtobool(x)), default=False, nargs=\"?\", const=True,\n",
        "        help=\"if toggled, this experiment will be tracked with Weights and Biases\")\n",
        "    parser.add_argument(\"--wandb-project-name\", type=str, default=\"ppo-implementation-details\",\n",
        "        help=\"the wandb's project name\")\n",
        "    parser.add_argument(\"--wandb-entity\", type=str, default=None,\n",
        "        help=\"the entity (team) of wandb's project\")\n",
        "    parser.add_argument(\"--capture-video\", type=lambda x: bool(strtobool(x)), default=False, nargs=\"?\", const=True,\n",
        "        help=\"weather to capture videos of the agent performances (check out `videos` folder)\")\n",
        "    # Algorithm specific arguments\n",
        "    parser.add_argument(\"--num-envs\", type=int, default=4,\n",
        "        help=\"the number of parallel game environments\")\n",
        "    parser.add_argument(\"--num-steps\", type=int, default=128,\n",
        "        help=\"the number of steps to run in each environment per policy rollout\")\n",
        "    parser.add_argument(\"--anneal-lr\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
        "        help=\"Toggle learning rate annealing for policy and value networks\")\n",
        "    parser.add_argument(\"--gae\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
        "        help=\"Use GAE for advantage computation\")\n",
        "    parser.add_argument(\"--gamma\", type=float, default=0.99,\n",
        "        help=\"the discount factor gamma\")\n",
        "    parser.add_argument(\"--gae-lambda\", type=float, default=0.95,\n",
        "        help=\"the lambda for the general advantage estimation\")\n",
        "    parser.add_argument(\"--num-minibatches\", type=int, default=4,\n",
        "        help=\"the number of mini-batches\")\n",
        "    parser.add_argument(\"--update-epochs\", type=int, default=10,\n",
        "        help=\"the K epochs to update the policy\")\n",
        "    parser.add_argument(\"--norm-adv\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
        "        help=\"Toggles advantages normalization\")\n",
        "    parser.add_argument(\"--clip-coef\", type=float, default=0.2,\n",
        "        help=\"the surrogate clipping coefficient\")\n",
        "    parser.add_argument(\"--clip-vloss\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
        "        help=\"Toggles whether or not to use a clipped loss for the value function, as per the paper.\")\n",
        "    parser.add_argument(\"--ent-coef\", type=float, default=0.01,\n",
        "        help=\"coefficient of the entropy\")\n",
        "    parser.add_argument(\"--vf-coef\", type=float, default=0.5,\n",
        "        help=\"coefficient of the value function\")\n",
        "    parser.add_argument(\"--max-grad-norm\", type=float, default=0.5,\n",
        "        help=\"the maximum norm for the gradient clipping\")\n",
        "    parser.add_argument(\"--target-kl\", type=float, default=None,\n",
        "        help=\"the target KL divergence threshold\") #should be set to 0.015 if wanna use\n",
        "    args, unknown = parser.parse_known_args()\n",
        "    args.batch_size = int(args.num_envs * args.num_steps)\n",
        "    args.minibatch_size = int(args.batch_size // args.num_minibatches)\n",
        "    # fmt: on\n",
        "    return args\n"
      ],
      "metadata": {
        "id": "usT6eGkSBp7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "## ----------------------------------------- PARSER ------------------------------------------------\n",
        "  # retrieve the parser\n",
        "  args = parse_args()\n",
        "  run_name = f\"{args.gym_id}__{args.exp_name}__{args.seed}__{int(time.time())}\"\n",
        "\n",
        "## -------------------------------------- W&B, TENSORBOARD ----------------------------------------\n",
        "\n",
        "  # weight and biases flag\n",
        "  if args.track:\n",
        "      import wandb\n",
        "\n",
        "      wandb.init(\n",
        "          project=args.wandb_project_name,\n",
        "          entity=args.wandb_entity,\n",
        "          sync_tensorboard=True,\n",
        "          config=vars(args),\n",
        "          name=run_name,\n",
        "          monitor_gym=True,\n",
        "          save_code=True,\n",
        "      )\n",
        "\n",
        "  # tensorboard setup\n",
        "  writer = SummaryWriter(f\"runs/{run_name}\")\n",
        "  writer.add_text(\n",
        "      \"hyperparameters\",\n",
        "      \"|param|value|\\n|-|-|\\n%s\" % (\"\\n\".join([f\"|{key}|{value}|\" for key, value in vars(args).items()])),\n",
        "  )\n",
        "\n",
        "  ## ------------------------------------- SETTING UP THE GAME -------------------------------------------\n",
        "\n",
        "  # TRY NOT TO MODIFY: seeding\n",
        "  random.seed(args.seed)\n",
        "  np.random.seed(args.seed)\n",
        "  torch.manual_seed(args.seed)\n",
        "  torch.backends.cudnn.deterministic = args.torch_deterministic\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() and args.cuda else \"cpu\")\n",
        "\n",
        "  # env setup\n",
        "  envs = vectorize_env(args.gym_id, args.seed, args.capture_video, run_name, args.num_envs)\n",
        "\n",
        "  # Agent setup\n",
        "  agent = Agent(envs).to(device)\n",
        "  #agent.print_summary(envs)\n",
        "  optimizer = optim.Adam(agent.parameters(), lr=args.learning_rate, eps=1e-5)\n",
        "\n",
        "\n",
        "  # initializing things\n",
        "  # ALGO Logic: Storage setup\n",
        "  obs = torch.zeros((args.num_steps, args.num_envs) + envs.single_observation_space.shape).to(device)\n",
        "  actions = torch.zeros((args.num_steps, args.num_envs) + envs.single_action_space.shape).to(device)\n",
        "  logprobs = torch.zeros((args.num_steps, args.num_envs)).to(device)\n",
        "  rewards = torch.zeros((args.num_steps, args.num_envs)).to(device)\n",
        "  dones = torch.zeros((args.num_steps, args.num_envs)).to(device)\n",
        "  values = torch.zeros((args.num_steps, args.num_envs)).to(device)\n",
        "\n",
        "## ------------------------------------- START THE GAME -------------------------------------------\n",
        "  # TRY NOT TO MODIFY: start the game\n",
        "  global_step = 0\n",
        "  start_time = time.time()\n",
        "  next_obs = torch.Tensor(envs.reset()).to(device)\n",
        "  next_done = torch.zeros(args.num_envs).to(device)\n",
        "  num_updates = args.total_timesteps // args.batch_size\n",
        "\n",
        "  for update in range(1, num_updates + 1):\n",
        "    #print('Starting update {}'.format(update))\n",
        "    # Annealing the rate if instructed to do so.\n",
        "    optimizer.param_groups[0][\"lr\"] = anneal(args.anneal_lr, update, num_updates, \\\n",
        "                                             args.learning_rate)\n",
        "\n",
        "    for step in range(0, args.num_steps):\n",
        "      # update global steps\n",
        "      global_step += 1 * args.num_envs\n",
        "      #update parameters\n",
        "      obs, actions, logprobs, rewards, dones, values, next_obs, next_done, info \\\n",
        "      = collect_data(envs, obs, actions, logprobs, rewards, dones, values, next_obs,\\\n",
        "                     next_done, agent, step, device)\n",
        "\n",
        "      # update tensorboard\n",
        "      if 'episode' in info.keys():\n",
        "        for item in info['episode']:\n",
        "          if item is not None:\n",
        "            #print(f\"global_step={global_step}, episodic_return={item['r']}\")\n",
        "            writer.add_scalar(\"charts/episodic_return\", item[\"r\"], global_step)\n",
        "            writer.add_scalar(\"charts/episodic_length\", item[\"l\"], global_step)\n",
        "\n",
        "    # general advantages estimation\n",
        "    returns, advantages = GAE(args.gae, args.gae_lambda, args.gamma, agent,\\\n",
        "        values, dones, rewards, next_obs, next_done,\\\n",
        "        args.num_steps, device)\n",
        "    # flatten the batch\n",
        "    b_obs = obs.reshape((-1,) + envs.single_observation_space.shape)\n",
        "    b_logprobs = logprobs.reshape(-1)\n",
        "    b_actions = actions.reshape((-1,) + envs.single_action_space.shape)\n",
        "    b_advantages = advantages.reshape(-1)\n",
        "    b_returns = returns.reshape(-1)\n",
        "    b_values = values.reshape(-1)\n",
        "\n",
        "## ------------------------------------- TRAINING LOOP ----------------------------------------------\n",
        "    v_loss, pg_loss, entropy_loss, old_approx_kl, approx_kl, clipfracs,\\\n",
        "    b_values, b_returns = PPO_train_agent(args.batch_size, args.update_epochs, args.minibatch_size, \\\n",
        "                                      args.clip_coef, args.norm_adv, args.clip_vloss,\\\n",
        "                                      args.ent_coef, args.vf_coef, args.max_grad_norm, args.target_kl,\\\n",
        "                                      agent, optimizer,\\\n",
        "                                      b_obs, b_actions,b_logprobs,\\\n",
        "                                      b_advantages, b_returns, b_values)\n",
        "\n",
        "## --------------------------------- UPDATING AND CLOSING UP -----------------------------------------\n",
        "    y_pred, y_true = b_values.cpu().numpy(), b_returns.cpu().numpy()\n",
        "    var_y = np.var(y_true)\n",
        "    explained_var = np.nan if var_y == 0 else 1 - np.var(y_true - y_pred) / var_y\n",
        "\n",
        "    # TRY NOT TO MODIFY: record rewards for plotting purposes\n",
        "    writer.add_scalar(\"charts/learning_rate\", optimizer.param_groups[0][\"lr\"], global_step)\n",
        "    writer.add_scalar(\"losses/value_loss\", v_loss.item(), global_step)\n",
        "    writer.add_scalar(\"losses/policy_loss\", pg_loss.item(), global_step)\n",
        "    writer.add_scalar(\"losses/entropy\", entropy_loss.item(), global_step)\n",
        "    writer.add_scalar(\"losses/old_approx_kl\", old_approx_kl.item(), global_step)\n",
        "    writer.add_scalar(\"losses/approx_kl\", approx_kl.item(), global_step)\n",
        "    writer.add_scalar(\"losses/clipfrac\", np.mean(clipfracs), global_step)\n",
        "    writer.add_scalar(\"losses/explained_variance\", explained_var, global_step)\n",
        "    #print(\"SPS:\", int(global_step / (time.time() - start_time)))\n",
        "    writer.add_scalar(\"charts/SPS\", int(global_step / (time.time() - start_time)), global_step)\n",
        "\n",
        "  envs.close()\n",
        "  writer.close()"
      ],
      "metadata": {
        "id": "BkibduJp2i6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1beb0ede-1d63-439b-aa5d-cb56a535d4d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:256: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/vector/vector_env.py:56: DeprecationWarning: \u001b[33mWARN: Initializing vector env in old step API which returns one bool array instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensorboard\n"
      ],
      "metadata": {
        "id": "sTzuojEmBIxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "h1dc7rW8-ImB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation\n",
        "Evaluate the agent"
      ],
      "metadata": {
        "id": "kzt9KAPX4fUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_ev, std_ev = evaluate_agent(args.gym_id, args.seed, run_name, device, agent)\n",
        "print('evaluation test:')\n",
        "print(mean_ev)\n",
        "print(std_ev)"
      ],
      "metadata": {
        "id": "rN6T_Qcc5H1I",
        "outputId": "661c21e6-9af5-4759-d93f-c5e610a6f0af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/record_video.py:78: UserWarning: \u001b[33mWARN: Overwriting existing videos at /content/evaluation_videos/CartPole-v1__Cart_Pole_simulation__1__1697550413 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:256: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/monitoring/video_recorder.py:78: DeprecationWarning: \u001b[33mWARN: Recording ability for environment CartPole-v1 initialized with `render_mode=None` is marked as deprecated and will be removed in the future.\u001b[0m\n",
            "  logger.deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting episode 0\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/envs/classic_control/cartpole.py:179: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned terminated = True. You should always call 'reset()' once you receive 'terminated = True' -- any further steps are undefined behavior.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e98YqYY2CgV6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PPO Main\n",
        "\n"
      ],
      "metadata": {
        "id": "wXelcCdk2E_-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing libraries"
      ],
      "metadata": {
        "id": "DOxSm9hy6S7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# useful for import notebook\n",
        "!pip install import-ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdNtKkPK6R_i",
        "outputId": "93c088b3-dc3f-4273-b162-e9b2c1c4334b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting import-ipynb\n",
            "  Downloading import_ipynb-0.1.4-py3-none-any.whl (4.1 kB)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.10/dist-packages (from import-ipynb) (7.34.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from import-ipynb) (5.9.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (67.7.2)\n",
            "Collecting jedi>=0.16 (from IPython->import-ipynb)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (4.8.0)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->import-ipynb) (2.18.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->import-ipynb) (4.19.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from nbformat->import-ipynb) (5.4.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->IPython->import-ipynb) (0.8.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.10.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->IPython->import-ipynb) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->import-ipynb) (0.2.8)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->nbformat->import-ipynb) (3.11.0)\n",
            "Installing collected packages: jedi, import-ipynb\n",
            "Successfully installed import-ipynb-0.1.4 jedi-0.19.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting things up for the environment"
      ],
      "metadata": {
        "id": "5FZrs3MKa4hl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cloning Fufi repo from git\n",
        "!git clone https://github.com/Gaianeve/gym-Fufi.git\n",
        "#installing things\n",
        "!pip install /content/gym-Fufi"
      ],
      "metadata": {
        "id": "7DgSKBq0an90",
        "outputId": "57f895d1-bc43-4756-ba20-203d4a10fa13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'gym-Fufi'...\n",
            "remote: Enumerating objects: 95, done.\u001b[K\n",
            "remote: Counting objects: 100% (95/95), done.\u001b[K\n",
            "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
            "remote: Total 95 (delta 23), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (95/95), 52.17 KiB | 3.48 MiB/s, done.\n",
            "Resolving deltas: 100% (23/23), done.\n",
            "Processing ./gym-Fufi\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## importing libraries and functions\n"
      ],
      "metadata": {
        "id": "zw5gxH9B2OLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#libraries\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "from distutils.util import strtobool\n",
        "import gym\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.distributions.categorical import Categorical\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "4Bsd8_M52bPt",
        "outputId": "5a45ef36-4b73-4deb-b5e4-8ce77132db21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/dtypes.py:35: DeprecationWarning: ml_dtypes.float8_e4m3b11 is deprecated. Use ml_dtypes.float8_e4m3b11fnuz\n",
            "  from tensorflow.tsl.python.lib.core import pywrap_ml_dtypes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import notebook functions\n",
        "import import_ipynb\n",
        "from Environment import vectorize_env\n",
        "from Agent_class import Agent\n",
        "from Agent_utils import anneal, collect_data, GAE, PPO_train_agent, evaluate_agent\n",
        "\n",
        "# Enter the environment directory\n",
        "%cd /content/gym-Fufi\n",
        "# Actually importing the library for our environment\n",
        "import gym_Fufi"
      ],
      "metadata": {
        "id": "2_myzRAg4q50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "68b85d6d-9149-4e9a-8be8-ec4bb8b80e4b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "importing Jupyter notebook from Environment.ipynb\n",
            "fatal: destination path 'gym-Fufi' already exists and is not an empty directory.\n",
            "Processing ./gym-Fufi\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-45ebd106c3e7>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# import notebook functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimport_ipynb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mEnvironment\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvectorize_env\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mAgent_class\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mAgent_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0manneal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollect_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGAE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPPO_train_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_backward_compatible\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/import_ipynb.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(self, fullname)\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_transformer_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;31m# run the code in themodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_user_ns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Environment.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2416\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2418\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2419\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-85>\u001b[0m in \u001b[0;36mcd\u001b[0;34m(self, parameter_s)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py\u001b[0m in \u001b[0;36mcd\u001b[0;34m(self, parameter_s)\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                 \u001b[0mcwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m                 \u001b[0mdhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_dh'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0moldcwd\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m                     \u001b[0mdhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '_dh'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PARSER ISSUE\n",
        "**Importing the parse_args() function from an another notebook doesn't work, so you need to define the function just ubove the main**\n",
        "\n",
        "For what I have understood, the point is that ther's some problem with the notebook interface, because is user-friendly."
      ],
      "metadata": {
        "id": "J2X7rIwyByOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_args():\n",
        "    # fmt: off\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--exp-name\", type=str, default= \"Fufi_adventures\",\n",
        "        help=\"the name of this experiment\")\n",
        "    parser.add_argument(\"--gym-id\", type=str, default=\"Fufi-v0\",\n",
        "        help=\"the id of the gym environment\")\n",
        "    parser.add_argument(\"--learning-rate\", type=float, default=2.5e-4,\n",
        "        help=\"the learning rate of the optimizer\")\n",
        "    parser.add_argument(\"--seed\", type=int, default=1,\n",
        "        help=\"seed of the experiment\")\n",
        "    parser.add_argument(\"--total-timesteps\", type=int, default= 600000,\n",
        "        help=\"total timesteps of the experiments\")\n",
        "    parser.add_argument(\"--torch-deterministic\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
        "        help=\"if toggled, `torch.backends.cudnn.deterministic=False`\")\n",
        "    parser.add_argument(\"--cuda\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
        "        help=\"if toggled, cuda will be enabled by default\")\n",
        "    parser.add_argument(\"--track\", type=lambda x: bool(strtobool(x)), default=False, nargs=\"?\", const=True,\n",
        "        help=\"if toggled, this experiment will be tracked with Weights and Biases\")\n",
        "    parser.add_argument(\"--wandb-project-name\", type=str, default=\"ppo-implementation-details\",\n",
        "        help=\"the wandb's project name\")\n",
        "    parser.add_argument(\"--wandb-entity\", type=str, default=None,\n",
        "        help=\"the entity (team) of wandb's project\")\n",
        "    parser.add_argument(\"--capture-video\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
        "        help=\"weather to capture videos of the agent performances (check out `videos` folder)\")\n",
        "    # Algorithm specific arguments\n",
        "    parser.add_argument(\"--num-envs\", type=int, default=4,\n",
        "        help=\"the number of parallel game environments\")\n",
        "    parser.add_argument(\"--num-steps\", type=int, default=128,\n",
        "        help=\"the number of steps to run in each environment per policy rollout\")\n",
        "    parser.add_argument(\"--anneal-lr\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
        "        help=\"Toggle learning rate annealing for policy and value networks\")\n",
        "    parser.add_argument(\"--gae\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
        "        help=\"Use GAE for advantage computation\")\n",
        "    parser.add_argument(\"--gamma\", type=float, default=0.99,\n",
        "        help=\"the discount factor gamma\")\n",
        "    parser.add_argument(\"--gae-lambda\", type=float, default=0.95,\n",
        "        help=\"the lambda for the general advantage estimation\")\n",
        "    parser.add_argument(\"--num-minibatches\", type=int, default=4,\n",
        "        help=\"the number of mini-batches\")\n",
        "    parser.add_argument(\"--update-epochs\", type=int, default=10,\n",
        "        help=\"the K epochs to update the policy\")\n",
        "    parser.add_argument(\"--norm-adv\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
        "        help=\"Toggles advantages normalization\")\n",
        "    parser.add_argument(\"--clip-coef\", type=float, default=0.2,\n",
        "        help=\"the surrogate clipping coefficient\")\n",
        "    parser.add_argument(\"--clip-vloss\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
        "        help=\"Toggles whether or not to use a clipped loss for the value function, as per the paper.\")\n",
        "    parser.add_argument(\"--ent-coef\", type=float, default=0.01,\n",
        "        help=\"coefficient of the entropy\")\n",
        "    parser.add_argument(\"--vf-coef\", type=float, default=0.5,\n",
        "        help=\"coefficient of the value function\")\n",
        "    parser.add_argument(\"--max-grad-norm\", type=float, default=0.5,\n",
        "        help=\"the maximum norm for the gradient clipping\")\n",
        "    parser.add_argument(\"--target-kl\", type=float, default=None,\n",
        "        help=\"the target KL divergence threshold\") #should be set to 0.015 if wanna use\n",
        "    args, unknown = parser.parse_known_args()\n",
        "    args.batch_size = int(args.num_envs * args.num_steps)\n",
        "    args.minibatch_size = int(args.batch_size // args.num_minibatches)\n",
        "    # fmt: on\n",
        "    return args\n"
      ],
      "metadata": {
        "id": "usT6eGkSBp7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "## ----------------------------------------- PARSER ------------------------------------------------\n",
        "  # retrieve the parser\n",
        "  args = parse_args()\n",
        "  run_name = f\"{args.gym_id}__{args.exp_name}__{args.seed}__{int(time.time())}\"\n",
        "\n",
        "## -------------------------------------- W&B, TENSORBOARD ----------------------------------------\n",
        "\n",
        "  # weight and biases flag\n",
        "  if args.track:\n",
        "      import wandb\n",
        "\n",
        "      wandb.init(\n",
        "          project=args.wandb_project_name,\n",
        "          entity=args.wandb_entity,\n",
        "          sync_tensorboard=True,\n",
        "          config=vars(args),\n",
        "          name=run_name,\n",
        "          monitor_gym=True,\n",
        "          save_code=True,\n",
        "      )\n",
        "\n",
        "  # tensorboard setup\n",
        "  writer = SummaryWriter(f\"runs/{run_name}\")\n",
        "  writer.add_text(\n",
        "      \"hyperparameters\",\n",
        "      \"|param|value|\\n|-|-|\\n%s\" % (\"\\n\".join([f\"|{key}|{value}|\" for key, value in vars(args).items()])),\n",
        "  )\n",
        "\n",
        "  ## ------------------------------------- SETTING UP THE GAME -------------------------------------------\n",
        "\n",
        "  # TRY NOT TO MODIFY: seeding\n",
        "  random.seed(args.seed)\n",
        "  np.random.seed(args.seed)\n",
        "  torch.manual_seed(args.seed)\n",
        "  torch.backends.cudnn.deterministic = args.torch_deterministic\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() and args.cuda else \"cpu\")\n",
        "\n",
        "  # env setup\n",
        "  envs = vectorize_env(args.gym_id, args.seed, args.capture_video, run_name, args.num_envs)\n",
        "\n",
        "  # Agent setup\n",
        "  agent = Agent(envs).to(device)\n",
        "  #agent.print_summary(envs)\n",
        "  optimizer = optim.Adam(agent.parameters(), lr=args.learning_rate, eps=1e-5)\n",
        "\n",
        "\n",
        "  # initializing things\n",
        "  # ALGO Logic: Storage setup\n",
        "  obs = torch.zeros((args.num_steps, args.num_envs) + envs.single_observation_space.shape).to(device)\n",
        "  actions = torch.zeros((args.num_steps, args.num_envs) + envs.single_action_space.shape).to(device)\n",
        "  logprobs = torch.zeros((args.num_steps, args.num_envs)).to(device)\n",
        "  rewards = torch.zeros((args.num_steps, args.num_envs)).to(device)\n",
        "  dones = torch.zeros((args.num_steps, args.num_envs)).to(device)\n",
        "  values = torch.zeros((args.num_steps, args.num_envs)).to(device)\n",
        "\n",
        "## ------------------------------------- START THE GAME -------------------------------------------\n",
        "  # TRY NOT TO MODIFY: start the game\n",
        "  global_step = 0\n",
        "  start_time = time.time()\n",
        "  next_obs = torch.Tensor(envs.reset()).to(device)\n",
        "  next_done = torch.zeros(args.num_envs).to(device)\n",
        "  num_updates = args.total_timesteps // args.batch_size\n",
        "\n",
        "  for update in range(1, num_updates + 1):\n",
        "    #print('Starting update {}'.format(update))\n",
        "    # Annealing the rate if instructed to do so.\n",
        "    optimizer.param_groups[0][\"lr\"] = anneal(args.anneal_lr, update, num_updates, \\\n",
        "                                             args.learning_rate)\n",
        "\n",
        "    for step in range(0, args.num_steps):\n",
        "      # update global steps\n",
        "      global_step += 1 * args.num_envs\n",
        "      #update parameters\n",
        "      obs, actions, logprobs, rewards, dones, values, next_obs, next_done, info \\\n",
        "      = collect_data(envs, obs, actions, logprobs, rewards, dones, values, next_obs,\\\n",
        "                     next_done, agent, step, device)\n",
        "\n",
        "      # update tensorboard\n",
        "      if 'episode' in info.keys():\n",
        "        for item in info['episode']:\n",
        "          if item is not None:\n",
        "            #print(f\"global_step={global_step}, episodic_return={item['r']}\")\n",
        "            writer.add_scalar(\"charts/episodic_return\", item[\"r\"], global_step)\n",
        "            writer.add_scalar(\"charts/episodic_length\", item[\"l\"], global_step)\n",
        "\n",
        "    # general advantages estimation\n",
        "    returns, advantages = GAE(args.gae, args.gae_lambda, args.gamma, agent,\\\n",
        "        values, dones, rewards, next_obs, next_done,\\\n",
        "        args.num_steps, device)\n",
        "    # flatten the batch\n",
        "    b_obs = obs.reshape((-1,) + envs.single_observation_space.shape)\n",
        "    b_logprobs = logprobs.reshape(-1)\n",
        "    b_actions = actions.reshape((-1,) + envs.single_action_space.shape)\n",
        "    b_advantages = advantages.reshape(-1)\n",
        "    b_returns = returns.reshape(-1)\n",
        "    b_values = values.reshape(-1)\n",
        "\n",
        "## ------------------------------------- TRAINING LOOP ----------------------------------------------\n",
        "    v_loss, pg_loss, entropy_loss, old_approx_kl, approx_kl, clipfracs,\\\n",
        "    b_values, b_returns = PPO_train_agent(args.batch_size, args.update_epochs, args.minibatch_size, \\\n",
        "                                      args.clip_coef, args.norm_adv, args.clip_vloss,\\\n",
        "                                      args.ent_coef, args.vf_coef, args.max_grad_norm, args.target_kl,\\\n",
        "                                      agent, optimizer,\\\n",
        "                                      b_obs, b_actions,b_logprobs,\\\n",
        "                                      b_advantages, b_returns, b_values)\n",
        "\n",
        "## --------------------------------- UPDATING AND CLOSING UP -----------------------------------------\n",
        "    y_pred, y_true = b_values.cpu().numpy(), b_returns.cpu().numpy()\n",
        "    var_y = np.var(y_true)\n",
        "    explained_var = np.nan if var_y == 0 else 1 - np.var(y_true - y_pred) / var_y\n",
        "\n",
        "    # TRY NOT TO MODIFY: record rewards for plotting purposes\n",
        "    writer.add_scalar(\"charts/learning_rate\", optimizer.param_groups[0][\"lr\"], global_step)\n",
        "    writer.add_scalar(\"losses/value_loss\", v_loss.item(), global_step)\n",
        "    writer.add_scalar(\"losses/policy_loss\", pg_loss.item(), global_step)\n",
        "    writer.add_scalar(\"losses/entropy\", entropy_loss.item(), global_step)\n",
        "    writer.add_scalar(\"losses/old_approx_kl\", old_approx_kl.item(), global_step)\n",
        "    writer.add_scalar(\"losses/approx_kl\", approx_kl.item(), global_step)\n",
        "    writer.add_scalar(\"losses/clipfrac\", np.mean(clipfracs), global_step)\n",
        "    writer.add_scalar(\"losses/explained_variance\", explained_var, global_step)\n",
        "    #print(\"SPS:\", int(global_step / (time.time() - start_time)))\n",
        "    writer.add_scalar(\"charts/SPS\", int(global_step / (time.time() - start_time)), global_step)\n",
        "\n",
        "  envs.close()\n",
        "  writer.close()"
      ],
      "metadata": {
        "id": "BkibduJp2i6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1beb0ede-1d63-439b-aa5d-cb56a535d4d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:256: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/vector/vector_env.py:56: DeprecationWarning: \u001b[33mWARN: Initializing vector env in old step API which returns one bool array instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensorboard\n"
      ],
      "metadata": {
        "id": "sTzuojEmBIxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "h1dc7rW8-ImB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation\n",
        "Evaluate the agent"
      ],
      "metadata": {
        "id": "kzt9KAPX4fUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_ev, std_ev = evaluate_agent(args.gym_id, args.seed, run_name, device, agent)\n",
        "print('evaluation test:')\n",
        "print(mean_ev)\n",
        "print(std_ev)"
      ],
      "metadata": {
        "id": "rN6T_Qcc5H1I",
        "outputId": "661c21e6-9af5-4759-d93f-c5e610a6f0af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/record_video.py:78: UserWarning: \u001b[33mWARN: Overwriting existing videos at /content/evaluation_videos/CartPole-v1__Cart_Pole_simulation__1__1697550413 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:256: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/monitoring/video_recorder.py:78: DeprecationWarning: \u001b[33mWARN: Recording ability for environment CartPole-v1 initialized with `render_mode=None` is marked as deprecated and will be removed in the future.\u001b[0m\n",
            "  logger.deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting episode 0\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/envs/classic_control/cartpole.py:179: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned terminated = True. You should always call 'reset()' once you receive 'terminated = True' -- any further steps are undefined behavior.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e98YqYY2CgV6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}